%
%   Chapter Experiment
%
%   Qing-Cheng Li (r01922024 at csie dot ntu dot edu dot tw)
%   R.O.C.103.07
%
\chapter{實驗結果與分析}
\label{c:exp}

本章進行了以樣式偵測特性的實驗，
以Wikipedia的文章作為模擬內容串流文件、
以YAGO的資料作為答案、
以PATTY提供的樣式對Wikipedia的文章進行偵測，
並介紹評估的標準以及對實驗結果的分析。

\section{測試資料集}
\label{s:dataset}

為了模擬內容串流文件，
本研究以Wikipedia的條目文章作為內容串流中的文件，
自2013年3月的Wikipedia Dumps\footnote{http://dumps.wikimedia.org/}擷取文件。

由於一開始並無文件中包含哪些實體特性的正確資料，
而YAGO的YAGO Facts提供了<subject, property, object>的資訊，
因此我們使用YAGO Facts的propety作為參考答案，
並將subject連結至Wikipedia的文章，
這樣就有每篇文件具有哪些特性的參考答案。

樣式則是使用PATTY提供的樣式釋義，其包含了知識庫定義的關係，
即本研究擬偵測之實體特性，以及可用以表達該特性之樣式集。
實驗採用的是其中的YAGO關係（YAGO Relations），一共有25組關係，
但其中一組關係（YAGO:Produced）在YAGO中沒有找到對映的Wikipedia條目，
因此僅對餘下24組關係進行實驗。

接下來只留下存在這24種特性的Wikipedia條目，
為了防止YAGO Facts中存在某特性但文章中卻根本沒有提及的狀況發生，
我們只留下<subject,property,object>中subject條目內有出現object字詞片段的特性留下，
若object內的字根本沒有出現在文章中，則捨去這個特性。
經過處理後，最後共有334,469篇條目作為測試資料集，
表\ref{t:yago-instance} 顯示了各個特性在測試資料集中的數量。

%t:yago-instance
\input{tables/yagoInstance}

表\ref{t:yago-coverage} 統計了在不同的信心值下與不同的樣式歧義下，
樣式的數量以及含有這些樣式的文件累計總數。
由表中可以看出其實當樣式歧義度超過5之後所涵蓋的累計文件增長速度已經趨於平緩，
因此本實驗最多將只採用歧義度不大於5的樣式進行。

%t:yago-coverage
\input{tables/yagoCoverage}

由於資料集內的Wikipeida條目皆是描寫實體，
在假設文章的內容都是以描寫該實體的前提下，
可以利用YAGO Simple Types作為該文描述實體之類型，
搭配樣式的領域（Domain）資訊輔助偵測。

而第\ref{c:method} 章中所提到需要利用過去的資料進行統計、訓練分類器，
則是將測試資料集分為五等份，以其中四等份作為過去的資料，
並對其進行計算可信賴度，以及利用字詞作為特徵，對每個特性訓練分類器。
餘下的一份進行測試，最後將五份結果平均為實驗結果。

\section{評估標準}
\label{s:eval}
在偵測系統的效率方面，
我們以每顆核心在每分鐘內可以處理多少文件來評估，
以及要達到TREC知識庫加速競賽的每小時處理約100,000篇的規模需要多少運算核心或機器。

在偵測系統的效能方面，
我們希望了解對每一個實體特性，
利用樣式自文章中偵測該特性的效能。
因此，以精確率（Precision）、召回率（Recall）、$F_1$分數（$F_1$ Score）進行評估。
精確率公式如式\ref{f:precision}，召回率公式如式\ref{f:recall}。

\begin{equation}
    \label{f:precision}
    Precision = \frac{|\{relevant\ documents\}\cap\{retrived\ documents\}|}{|\{retrived\ documents\}|}
\end{equation}

\begin{equation}
    \label{f:recall}
    Recall = \frac{|\{relevant\ documents\}\cap\{retrived\ documents\}|}{|\{relevant\ documents\}|}
\end{equation}

實驗流程中樣式比對、特性消歧義等步驟皆以句子為單位進行實驗，
本因針對每個句子的偵測結果進行評估，
但由於缺乏實例層級的答案資訊，
僅有透過YAGO實體引申至Wikipedia條目文章的特性資訊，
因此將條目文章中所有的句子所產生的實體特性皆視為屬於該條目所指之實體，
並以條目為單位進行精確率與召回率的計算。

以文章為單位進行計算，
遇到文章中句子所產生的實體特性不屬於文章所指之實體，
又或者在別的文章中的句子產生了屬於文章所指之實體的特性，
遇到這兩種狀況皆無法處理與評估。

對於一個實體特性，經過偵測之後會有被標為有此特性的文件與無此特性的文件。
其中，相關的文件（Relevant documents）即真正存在該特性之文件；
尋回的文件（Retrived documents）即偵測系統標記為擁有此特性之文件。
精確率評估在尋回的文件之中有多少文件真正存在該特性；
召回率評估在真正擁有該特性的文件中有多少被系統偵測到。

$F_1$分數則是綜合評估精確率與召回率，計算方式如式\ref{f:f1}，為精確率與召回率的調和平均。

\begin{equation}
    \label{f:f1}
    F_1\ Score = \frac{2\times Precision \times Recall}{Precision + Recall}
\end{equation}

除了評估個別特性的效能之外，以宏觀平均（Macro Average）及微觀平均（Mirco Average）分別計算精確率與召回率及$F_1$分數來評估整體效能。
以精確率為例，宏觀平均的計算如式\ref{f:macro}，
而微觀平均的計算則如式\ref{f:micro}。

\begin{equation}
    \label{f:macro}
    Macro\ Avg\ Precision=\frac{\sum_i^n precision_i}{n}
\end{equation}

\begin{equation}
    \label{f:micro}
    Mirco\ Avg\ Precision=\frac{\sum_i^n |\{relevant\ documents\}_i|\cap|\{retrived\ documents\}_i|}{\sum_i^n |\{retrived\ documents\}_i|}
\end{equation}


\section{實驗結果}
\label{s:result}

\subsection{效率}
在圖\ref{i:process-v2}的偵測流程之中，本實驗將其拆解為兩個部份來評估效能。
前半部份為樣式比對的效率，後半部份為特性消歧義的效率。

樣式比對的效率在時脈為2.5GHz的中央處理器為每顆核心每分鐘592份文件，
特性消歧義的效率在同樣條件下為每顆核心每分鐘2750份文件。
要在一小時內處理100,000文件僅需要3顆核心即可完成。
而本實驗使用一台配備時脈2.5GHz、24核心中央處理器的工作站僅需半小時即可處理完全部約330,000份文件。

\subsection{原始效能}
依照圖\ref{i:process-v2} 的流程，
但在樣式篩選的部分僅篩選了無歧義度以及歧義度不大於5的樣式，
而無特性消歧義的結果如表\ref{t:baseline-1}。
表中左半部是每一個特性使用無歧義度，也就是歧義度為1的樣式，
進行特性偵測的結果，由於沒有歧義問題，所以無需進行特性消歧義。

右半部則使用了歧義度不大於5的樣式，
也就是包含了無歧義、歧義度2至5的樣式，而不進行特性消歧義，
可以看到的結果是，由於沒有進行特性消歧義而的對每篇文章回答盡可能多的特性，
因此召回率提升，但精確率也因此下降，$F_1$分數則因為精確率降太多而變低。

由此也可以看出太寬鬆地依據樣式回報特性會降低效能，
後續的實驗將陸續加入樣式篩選與特性消歧義的方法， 嘗試改善效能。

%t:baseline-1
\input{tables/baseline-1}

\subsection{樣式篩選}
\subsubsection{信心值}
我們利用PATTY提供的信心值進行樣式的篩選，選定了門檻值分別為0（沒有門檻）、0.7、0.8與0.9，
只使用樣式信心值大於門檻值的樣式進行偵測實驗，其結果的宏觀平均與微觀平均$F_1$分數如圖\ref{i:conf-f1} 所示。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-conf-f1}
    \caption{無歧義度下F1分數平均隨信心值變化圖}
    \label{i:conf-f1}
\end{figure}

就整體效能而言，設定信心值門檻值並沒有辦法提升系統效能，反而使效能變差。
這是由於設定門檻值後，通過門檻值的樣式數量減少，導致召回率下降太多，
到門檻值為0.9時，有部分的特性（hasCapital, isKnownFor）已經沒有可用的樣式。
但部分的特性$F_1$分數因精確率比較大幅度的提升而略微上升，表\ref{t:confidence} 中，
信心值門檻由0.8昇至0.9，
特性actedIn、created、diedIn、hasAcademicAdvisor、holdsPoliticalPosition、influences、isMarriedTo等的精確率皆有較大幅度的提升。

%t:confidence-f1
\input{tables/confidence.exp}

\subsubsection{可信賴度}
透過了過去的統計資料，也就是過去樣式出現時具有特性的比例，對可信賴度進行實驗。
設定了比例為0、0.3與0.5三個門檻值。

實驗的結果呈現如圖\ref{i:reliability-f1}，可以看出當門檻值調整至0.3時，
整體系統效能有提升，但再向上調整時就沒有太多上升。
原因是因為當門檻值提升至0.5時，
有些特性（hasCapital、holdsPoliticalPosition、isKnownFor、isLeaderOf、isPoliticianOf、participatedIn）已經沒有可用的樣式。
可信賴度的門檻設定留下了在過去文件中對精確率來說比較好的樣式，
由表\ref{t:reliability} 也可以看到精確率隨著門檻值提高而升高，
當然因為使用的樣式越來越少，所以召回率也隨之下降。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-reliability-f1}
    \caption{無歧義度下F1分數平均隨可信賴度變化圖}
    \label{i:reliability-f1}
\end{figure}

% t:reliability 
\input{tables/reliability.exp}

\subsubsection{歧義度}
由表\ref{t:yago-coverage} 觀察，當歧義度不超過5時所能涵蓋的文件數量就已經非常多了，
因此這裡測試了歧義度累計由1到5，也就是使用歧義度1的樣式、
使用歧義度1至2的樣式、使用歧義度1至3的樣式、使用歧義度1至4的樣式、
使用歧義度1至5的樣式一共5組實驗觀察系統效能的變化結果如圖\ref{i:degree}，
由於使用越來越多的樣式，因此召回率快速提高，
但也因此有了歧義問題，使得精確率下降，也讓$F_1$分數下降。
由於有歧義問題，後續的實驗將嘗試消歧義的方法與分析結果。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-degree}
    \caption{F1分數與召回率隨歧義度變化圖}
    \label{i:degree}
\end{figure}

經過了對信心值、可信賴度與歧義度的實驗，
可以知道透過篩選信心值與可信賴度可以提升精確率，
而使用歧義度高的樣式時可以提升召回率。

\subsection{特性消歧義}
\subsubsection{實體類型資訊}
由於特性具有領域與範圍，
這裡假設文章中的語句所描述的對象都是條目名稱所指之實體，
便可以利用實體的類型資訊與特性領域進行比對，將不合類型的特性消除掉。
例如Wikipedia條目Jahsha Bluntt是描述實體Jahsha這位籃球員，
文章中出現了actedIn的樣式，但actedIn的領域是演員，
因此可將actedIn消除掉。
加入實體類型資訊後，將不可能屬於實體的特性消除掉，在評估方面，
便不會使召回率下降，還有機會可以提升精確率。

圖\ref{i:type}便是加入實體類型資訊前後對不同歧義度的效能比較結果。
加入實體類型資訊後，使得精確率有大幅提升，
例如以使用歧義度不大於2的樣式時，如表\ref{t:type} 數據所示，
actedIn的False Postive從13,560降至489、happendIn的False Postive從1,567降至89，都有大幅度的精確率提升，
甚至是本來精確率就已經很高的isLocatedIn都有相當提升（False Postive從4,771下降至455）。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-type}
    \caption{加入實體類型資訊前後效能比較}
    \label{i:type}
\end{figure}

%t:t:type
\input{tables/type.exp.tex}

\subsubsection{特性篩選}
當使用具有特性歧義的樣式時，必須設法消除歧義。
而這裡的特性選擇是多選多的問題，以下實驗了幾種挑選特性的策略：
(1) 只選擇一個特性、 (2) 篩選門檻0.5、 (3) 篩選門檻0.75、 (4) 全選。

其中(1)、(2)、(3)利用過去文件所計算之可信賴度，
(1)選擇正確率最高的特性，
(2)與(3)將可信賴度正規化後，選擇門檻值以上之特性。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-macro-nol}
    \caption{不同歧義度下篩選策略效能表現（宏觀平均）}
    \label{i:macro-nol}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-micro-nol}
    \caption{不同歧義度下篩選策略效能表現（微觀平均）}
    \label{i:micro-nol}
\end{figure}

圖\ref{i:macro-nol}、\ref{i:micro-nol}呈現實驗結果，
(1)只選擇了一個忽略了可能有複數個特性存在，
(4)全選則太寬鬆，以至於精確率降太多。

由巨觀平均的角度來看，
在使用任何歧義度之樣式的情況下，
設定0.5的正確篩選門檻的表現都來得比其他策略還要好，
基本上都是精確率小幅提升，而召回率沒有太大改變。
是一個介於(1)和(4)之間的折衷策略。

從微觀平均的角度來看，
則是篩選門檻0.75的表現比較好，
越高的篩選門檻使得能夠被選擇的特性數量減少，
False Postive也隨之減少，
特性hasChild的False Postive較篩選門檻0.5少了約一萬份的文件，
佔整體降幅約一半，使得門檻0.75的微觀平均表現較好。

\subsubsection{簡單貝氏分類器}
由於樣式有出現仍不一定具有特性，我們認為這與樣式出現的前後文可能有關聯，
因此針對每個特性，以過去的文件訓練了24個簡單貝氏分類器。
當樣式出現時，以分類器將樣式出現的句子分為存在或不存在該特性。

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{images/04-nbc}
    \caption{使用簡單貝氏分類器前後效能比較}
    \label{i:nbc}
\end{figure}

%t:nbc
\input{tables/nbc.exp}

圖\ref{i:nbc} 顯示了使用簡單貝氏分類器對不同歧義度的效能比較。
而表\ref{t:nbc} 則是歧義度不小於5、使用實體類型資訊、樣式篩選門檻0.5時有無使用分類器的效能比較。

圖\ref{i:nbc} 與表\ref{t:nbc} 中可以看到使用了分類器後整體的效能有了大幅度的提升，
從個別特性來看，大多數的特性的精確度都有了大幅的提升。
而isKnownFor、isPoliticianOf則是因為有這些特性訓練時正面的句子太少，
以至於分類時完全沒有正向的結果。
表\ref{t:yago-instance} 也顯示這兩個特性的文件數與其他特性比起來算是比較少了些。

\subsection{錯誤分析}

不管是整體或個別特性偵測的效能以精確率、召回率作為評估標準，
其中False Postive對此二指標的影響甚巨，
因此我們分析了造成False Postive的原因。
由於實驗是經過樣式比對、特性消歧義等步驟，
若經過了特性消歧義仍然沒有回答出正確的特性，
那就造成了False Postive。

False Postive的成因基本上可以分成兩類。
第一類是在候選的特性中沒有選擇出正確的特性，
這代表選擇其他的特性就有機會答對，但這隱含了有樣式出現就一定要選擇特性。
第二類是樣式有出現，但根本不存在特性。

圖\ref{i:error}分析了使用分類器前後個特性的False Postive中的成分，
圖中的黑、白線條就是使用分類器前後第二類錯誤佔所有錯誤中的比例。
其實大多數的錯誤都是屬於第二類錯誤，
使用了分類器後第二類在部分特性中所占的比例有略微下降，
但然仍是最大宗的錯誤，要如何有效地克服這些錯誤是未來的研究課題之一。

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{images/04-error}
    \caption{使用簡單貝氏分類器前後錯誤分析}
    \label{i:error}
\end{figure}

